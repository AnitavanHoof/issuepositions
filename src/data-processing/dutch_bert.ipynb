{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66e542fc-8431-4224-ab9b-c728bfec0ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "checkpoint = \"FremyCompany/roberta-large-nl-oscar23\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97af045b-27e1-441c-bb8d-0a081e261142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00f6424643130aff606b0090fd9ae52c5b493fa3e4bb2e...</td>\n",
       "      <td>1</td>\n",
       "      <td>denk om stemmers met beperking\\nDemissionair m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01438633bd578448fb672c93fc34addb40769a2988ab24...</td>\n",
       "      <td>0</td>\n",
       "      <td>07:16\\nChris Stoffer, lijsttrekker SGP, bij Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02cba6b801518598e5f2d2a34ef8677a6d254e9494a3ab...</td>\n",
       "      <td>0</td>\n",
       "      <td>17:18\\nSchoonmaakactie besmeurde spandoeken BB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>036e9a7d0720f4a36e03b1ca870a0f37a4c850b911918a...</td>\n",
       "      <td>1</td>\n",
       "      <td>In aanloop naar de verkiezingen wordt de kas v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393898b66b7c3891c8cc545fd3356143dff0951cc15f8...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nFvD-leider Thierry Baudet gaat door met zijn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             unit_id  label  \\\n",
       "0  00f6424643130aff606b0090fd9ae52c5b493fa3e4bb2e...      1   \n",
       "1  01438633bd578448fb672c93fc34addb40769a2988ab24...      0   \n",
       "2  02cba6b801518598e5f2d2a34ef8677a6d254e9494a3ab...      0   \n",
       "3  036e9a7d0720f4a36e03b1ca870a0f37a4c850b911918a...      1   \n",
       "4  0393898b66b7c3891c8cc545fd3356143dff0951cc15f8...      0   \n",
       "\n",
       "                                                text  \n",
       "0  denk om stemmers met beperking\\nDemissionair m...  \n",
       "1  07:16\\nChris Stoffer, lijsttrekker SGP, bij Ra...  \n",
       "2  17:18\\nSchoonmaakactie besmeurde spandoeken BB...  \n",
       "3  In aanloop naar de verkiezingen wordt de kas v...  \n",
       "4  \\nFvD-leider Thierry Baudet gaat door met zijn...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the data from units (sentences) and annotations\n",
    "\n",
    "from pathlib import Path\n",
    "data = Path(\"../../data\")\n",
    "\n",
    "label2id  = {\"Ja\": 1, \"Nee\": 0}\n",
    "\n",
    "annotations = pd.read_csv(data / \"intermediate/annoations_01_dutch_types.csv\")\n",
    "annotations = annotations.rename(columns={\"issue position\": \"label\"})[[\"unit_id\", \"label\"]]\n",
    "annotations.label = annotations.label.map(label2id)\n",
    "\n",
    "units = pd.read_csv(data / \"intermediate/units_tk2023.csv\")\n",
    "units = units.fillna(\"\")\n",
    "units.text = units.before + \"\\n\" + units.text + \"\\n\" + units.after\n",
    "units = units[[\"unit_id\", \"text\"]]\n",
    "\n",
    "df = annotations.merge(units, on=\"unit_id\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3045523e-f4f8-4fe9-8995-e1d396c96c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some utility functions\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import datasets\n",
    "\n",
    "def get_datasets(data, train_ics, test_ics, checkpoint):\n",
    "    df_train = data.iloc[train_ics]\n",
    "    df_test =  data.iloc[test_ics]\n",
    "    \n",
    "    dataset = datasets.DatasetDict({\n",
    "        \"train\": datasets.Dataset.from_pandas(df_train),\n",
    "        \"test\": datasets.Dataset.from_pandas(df_test)\n",
    "    })\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "    def preprocess_function(examples):\n",
    "        return tokenizer(examples[\"text\"], truncation=True, padding=True)\n",
    "\n",
    "    dataset = dataset.map(preprocess_function, batched=True)\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)    \n",
    "    return dataset, data_collator, tokenizer \n",
    "   \n",
    "def predict_test(trainer, data):\n",
    "    predictions = trainer.predict(data)\n",
    "    preds = np.argmax(predictions.predictions, axis=-1)\n",
    "    return pd.DataFrame(dict(true=data['label'], pred=list(preds)))\n",
    "\n",
    "\n",
    "\n",
    "def get_model(label2id, checkpoint):\n",
    "    id2label = {v:k for (k,v) in label2id.items()}\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "       checkpoint, num_labels=2, id2label=id2label, label2id=label2id\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    metric = datasets.load_metric('f1')\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels, average=\"macro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b11ad59-e80f-4a5a-b790-827ce0e417d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wva/issuepositions/.venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(data / \"tmp/dutch_bert\"),\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=48,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    fp16_full_eval=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a612b22a-5934-438c-8132-668b7f5bcf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************** FOLD 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FremyCompany/roberta-large-nl-oscar23 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f3fda4d5ae459992da1449ae90ebc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac524264509436d8f567ece72075a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/298 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='266' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [266/375 00:53 < 00:22, 4.95 it/s, Epoch 3.53/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.559457</td>\n",
       "      <td>0.770266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.564726</td>\n",
       "      <td>0.789374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.661592</td>\n",
       "      <td>0.776161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wva/issuepositions/.venv/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/wva/issuepositions/.venv/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/wva/issuepositions/.venv/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Run k-fold crossvalidation, store predictions\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "splits = list(StratifiedKFold(n_splits=5).split(np.zeros(df.shape[0]), df.label))\n",
    "\n",
    "import torch, gc\n",
    "\n",
    "predictions=[]\n",
    "for i, (train_ics, test_ics) in enumerate(splits):\n",
    "    print(\"**************** FOLD\", i+1) \n",
    "    model=get_model(label2id, checkpoint)\n",
    "    dataset, collator, tokenizer = get_datasets(df, train_ics, test_ics, checkpoint)\n",
    "    trainer = Trainer(\n",
    "            model,\n",
    "            training_args,\n",
    "            train_dataset=dataset[\"train\"],\n",
    "            eval_dataset=dataset[\"test\"],\n",
    "            data_collator=collator,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics=compute_metrics,\n",
    "    )\n",
    "    trainer.train()\n",
    "    pred = predict_test(trainer, dataset['test'])\n",
    "    predictions.append(pred)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "97f5ada6-bb4f-4cfd-a9f7-99e15afeb521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86       863\n",
      "           1       0.81      0.81      0.81       625\n",
      "\n",
      "    accuracy                           0.84      1488\n",
      "   macro avg       0.84      0.84      0.84      1488\n",
      "weighted avg       0.84      0.84      0.84      1488\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "preds = pd.concat(predictions)\n",
    "print(classification_report(preds.true, preds.pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
